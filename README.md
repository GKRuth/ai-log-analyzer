(https://github.com/user-attachments/files/22005649/n_8_n_telegram_loki_reports_git_hub_package.1.md)
# n8n-telegram-loki-reports

–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –Ω–∞ **n8n** —Å ¬´—É–º–Ω—ã–º–∏¬ª –æ—Ç—á—ë—Ç–∞–º–∏ –æ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö (Loki + Grafana), Prometheus/Node Exporter –¥–ª—è –º–µ—Ç—Ä–∏–∫. –û—Ä–∏–µ–Ω—Ç–∏—Ä: –æ–¥–Ω–∞ –í–ú (\~7‚ÄØ–ì–ë RAM), –≤—Å—ë –≤ Docker. –ú–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –≤–Ω–µ—à–Ω–∏–º LLM (OpenRouter) –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–º (Ollama/LM Studio).

---

## üì¶ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```text
.
‚îú‚îÄ README.md                  # —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ
‚îú‚îÄ docker-compose.yml         # –±—ã—Å—Ç—Ä—ã–π –ø–æ–¥—ä—ë–º –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
‚îú‚îÄ .env.example               # —à–∞–±–ª–æ–Ω –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (–∫–æ–ø–∏—Ä—É–π –≤ .env)
‚îú‚îÄ n8n/
‚îÇ  ‚îú‚îÄ workflows/
‚îÇ  ‚îÇ  ‚îú‚îÄ bot-and-reports.example.json    # –∏–º–ø–æ—Ä—Ç –≤ n8n (–∑–∞–≥–ª—É—à–∫–∞, —Å–º. –Ω–∏–∂–µ)
‚îÇ  ‚îÇ  ‚îî‚îÄ probes.example.json             # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±—ã A/B/C –¥–ª—è –¥–µ–±–∞–≥–∞
‚îÇ  ‚îî‚îÄ snippets/                          # –∫–æ–¥ Function-—É–∑–ª–æ–≤ (–∫–æ–ø–∏–ø–∞—Å—Ç –≤ UI n8n)
‚îÇ     ‚îú‚îÄ init_start_timer.js
‚îÇ     ‚îú‚îÄ build_log.js
‚îÇ     ‚îú‚îÄ make_loki_window.js
‚îÇ     ‚îú‚îÄ build_metrics_and_prompt.js
‚îÇ     ‚îú‚îÄ extract_summary_merge.js
‚îÇ     ‚îú‚îÄ build_report_text.js
‚îÇ     ‚îú‚îÄ probe_A_build_log.js
‚îÇ     ‚îú‚îÄ probe_B_fetch_loki.js
‚îÇ     ‚îî‚îÄ probe_C_metrics_summary.js
‚îú‚îÄ grafana/
‚îÇ  ‚îú‚îÄ provisioning/
‚îÇ  ‚îÇ  ‚îú‚îÄ datasources/datasource.yml      # Loki/Prometheus –ø–æ–¥—Ö–≤–∞—Ç—è—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
‚îÇ  ‚îÇ  ‚îî‚îÄ dashboards/dashboards.yml
‚îÇ  ‚îî‚îÄ dashboards/
‚îÇ     ‚îî‚îÄ n8n-telegram.json               # –ø—Ä–∏–º–µ—Ä –¥–∞—à–±–æ—Ä–¥–∞ (p95, –æ—à–∏–±–∫–∏, —Å—á—ë—Ç—á–∏–∫–∏)
‚îú‚îÄ loki/
‚îÇ  ‚îî‚îÄ config/loki-config.yml
‚îú‚îÄ promtail/
‚îÇ  ‚îî‚îÄ config/promtail-config.yml
‚îú‚îÄ prometheus/
‚îÇ  ‚îî‚îÄ prometheus.yml
‚îî‚îÄ docs/
   ‚îî‚îÄ architecture.mmd                   # –¥–∏–∞–≥—Ä–∞–º–º–∞ (Mermaid)
```

> **–í–∞–∂–Ω–æ:** —Å—é–¥–∞ **–Ω–µ –∫–ª–∞–¥—ë–º —Å–µ–∫—Ä–µ—Ç—ã**. –í—Å–µ —Ç–æ–∫–µ–Ω—ã ‚Äî —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ `.env` –∏–ª–∏ Portainer ‚Üí Env.

---

## üß≠ –ß—Ç–æ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç (–∫–æ—Ä–æ—Ç–∫–æ)

- –í–µ—Ä—à–∏–Ω–∞: –æ–±—ã—á–Ω—ã–π —á–∞—Ç-–±–æ—Ç.
- –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∑–∞–Ω—è–ª **>‚ÄØ60‚ÄØ—Å–µ–∫**, n8n —Å–æ–±–∏—Ä–∞–µ—Ç –æ–∫–Ω–æ –ª–æ–≥–æ–≤ –∏–∑ **Loki**, —Å—á–∏—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–∞–Ω–∞–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, `@slow_reports_xyz`).
- Observability: Grafana (–¥–∞—à–±–æ—Ä–¥—ã), Prometheus + node\_exporter.

–î–∏–∞–≥—Ä–∞–º–º–∞:

```mermaid
flowchart LR
  tg[Telegram] -->|Webhook| n8n
  subgraph n8n
    T[Telegram Trigger]
    C2[Code2 / sim (/testslow)]
    IT[Init & Start Timer]
    LLM[Chat Model]
    ENS[Ensure Text]
    SEND[Telegram Send Message]
    BL[Build Log]
    P2L[Push to Loki]
    IF{latency_ms > 60s}
    MW[Make Loki Window]
    FL[Fetch Loki Window]
    BM[Build Metrics & Prompt]
    AR[Analyze (LLM/Off)]
    ES[Extract Summary]
    BT[Build Report Text]
    SENDCH[Telegram ‚Üí Reports Channel]
  end

  T-->C2-->IT-->LLM-->ENS-->SEND-->BL-->P2L-->IF
  IF -- true --> MW --> FL --> BM --> AR --> ES --> BT --> SENDCH

  subgraph observability
    Loki
    Promtail
    Grafana
    Prometheus
  end

  P2L --> Loki
  Promtail --> Loki
  Grafana --> Loki
  Grafana --> Prometheus
  node_exporter((node_exporter)) --> Prometheus
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

1. **–°–∫–ª–æ–Ω–∏—Ä—É–π** –∏ —Å–æ–∑–¥–∞–π `.env`:

```bash
cp .env.example .env
# –æ—Ç–∫—Ä–æ–π .env –∏ –∑–∞–ø–æ–ª–Ω–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (—Ç–æ–∫–µ–Ω—ã, URL –∏ —Ç.–¥.)
```

2. **Docker network** (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –≤–Ω–µ—à–Ω—é—é `proxy`):

```bash
docker network create proxy || true
```

3. **–ü–æ–¥–Ω–∏–º–∏ —Å—Ç–µ–∫**:

```bash
docker compose up -d
```

4. **–ó–∞–π–¥–∏ –≤ n8n** ‚Üí `http://<host>:5678` ‚Üí **Settings ‚Üí Import** –∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π —Ñ–∞–π–ª `n8n/workflows/bot-and-reports.example.json` (–∏–ª–∏ —Å–æ–±–µ—Ä–∏ –ø–æ —Å–Ω–∏–ø–ø–µ—Ç–∞–º –Ω–∏–∂–µ).

5. **Grafana** ‚Üí `http://<host>:3000` (–ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é admin/admin, –∏–∑–º–µ–Ω–∏) ‚Äî –¥–æ–ª–∂–Ω—ã –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç—å—Å—è –¥–∞—Ç–∞-—Å–æ—Ä—Å—ã –∏ –ø—Ä–∏–º–µ—Ä –¥–∞—à–±–æ—Ä–¥.

6. **–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç**: –¥–æ–±–∞–≤—å –±–æ—Ç–∞ –≤ –∫–∞–Ω–∞–ª –æ—Ç—á—ë—Ç–æ–≤ **–∞–¥–º–∏–Ω–æ–º**, Chat ID –º–æ–∂–Ω–æ —á–∏—Å–ª–æ–º (`REPORT_CHAT_ID`).

> –î–ª—è —Ä–∞–±–æ—Ç—ã —Å **–ª–æ–∫–∞–ª—å–Ω—ã–º LLM** (Ollama/LM Studio) —Å–º. —Ä–∞–∑–¥–µ–ª ¬´–õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å¬ª –Ω–∏–∂–µ.

---

## üîß –ö–æ–Ω—Ñ–∏–≥–∏ –∏ —Ñ–∞–π–ª—ã (–∫–æ–ø–∏–ø–∞—Å—Ç)

### `.env.example`

```dotenv
# ‚îÄ‚îÄ –ë–æ—Ç/–∫–∞–Ω–∞–ª ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TELEGRAM_BOT_TOKEN=__PUT_YOUR_TOKEN__
REPORT_CHAT_ID=-100xxxxxxxxxx

# ‚îÄ‚îÄ n8n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
N8N_HOST=0.0.0.0
N8N_PORT=5678
N8N_ENCRYPTION_KEY=__GENERATE_RANDOM_32_CHARS__
N8N_BASIC_AUTH_ACTIVE=false
N8N_BASIC_AUTH_USER=
N8N_BASIC_AUTH_PASSWORD=

# ‚îÄ‚îÄ LLM (–≤–Ω–µ—à–Ω–∏–π –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –í–∞—Ä–∏–∞–Ω—Ç A: OpenRouter (–≤–Ω–µ—à–Ω–∏–π)
OPENROUTER_API_KEY=__PUT_YOUR_OPENROUTER_KEY__
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_MODEL=google/gemini-2.5-flash-lite

# –í–∞—Ä–∏–∞–Ω—Ç B: –ª–æ–∫–∞–ª—å–Ω–∞—è LLM (Ollama/LM Studio) ‚Äî –ø—Ä–∏–º–µ—Ä
# LLM_BASE_URL=http://ollama:11434/v1
# LLM_MODEL=gemma2:2b-instruct
# LLM_API_KEY=ollama

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä—É–±–∏–ª—å–Ω–∏–∫ LLM (1=–≤–∫–ª, 0=–≤—ã–∫–ª)
LLM_ENABLED=1
MAX_LLM_CALLS_PER_DAY=500

# ‚îÄ‚îÄ Loki/Grafana/Prometheus ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
LOKI_URL=http://loki:3100
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin
PROMETHEUS_SCRAPE_INTERNAL=true
```

### `docker-compose.yml`

```yaml
version: "3.9"

services:
  n8n:
    image: n8nio/n8n:1.107.4
    restart: unless-stopped
    env_file: [.env]
    environment:
      - N8N_HOST=${N8N_HOST}
      - N8N_PORT=${N8N_PORT}
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - GENERIC_TIMEZONE=Europe/Moscow
      - NODE_FUNCTION_ALLOW_BUILTIN=buffer,crypto
      - NODE_FUNCTION_ALLOW_EXTERNAL=
      - WEBHOOK_URL=
      - LOKI_URL=${LOKI_URL}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - LLM_BASE_URL=${LLM_BASE_URL}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_ENABLED=${LLM_ENABLED}
      - MAX_LLM_CALLS_PER_DAY=${MAX_LLM_CALLS_PER_DAY}
      - REPORT_CHAT_ID=${REPORT_CHAT_ID}
    ports:
      - "5678:5678"
    volumes:
      - n8n-data:/home/node/.n8n
    networks: [proxy]

  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks: [proxy]
    depends_on: [loki]

  loki:
    image: grafana/loki:latest
    restart: unless-stopped
    command: ["-config.file=/etc/loki/local-config.yaml"]
    volumes:
      - ./loki/config/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    ports:
      - "3100:3100"
    networks: [proxy]

  promtail:
    image: grafana/promtail:latest
    restart: unless-stopped
    command: ["-config.file=/etc/promtail/config.yml"]
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./promtail/config/promtail-config.yml:/etc/promtail/config.yml:ro
    networks: [proxy]

  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks: [proxy]

  node_exporter:
    image: prom/node-exporter:latest
    restart: unless-stopped
    pid: host
    network_mode: host

volumes:
  n8n-data:
  grafana-data:
  loki-data:
  prometheus-data:

networks:
  proxy:
    external: true
```

### `n8n/snippets/init_start_timer.js`

```js
// Init & Start Timer ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º started_at, request_id –∏ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
const m = $json.message || $json.edited_message || {};
const started = $json.started_at ?? Date.now();
const reqId = $json.request_id ?? Math.random().toString(36).slice(2,10).toUpperCase();

return [{
  json: {
    started_at: started,
    request_id: reqId,
    chat_id: m.chat?.id ?? $json.chat_id,
    user_id: m.from?.id ?? $json.user_id,
    message_id: m.message_id ?? $json.message_id,
    text: (m.text ?? '').slice(0, 1500),
    has_image: !!(m.photo && m.photo.length),
    input: m.text ?? '' // –µ—Å–ª–∏ Memory –∂–¥—ë—Ç input
  }
}];
```

### `n8n/snippets/build_log.js`

```js
// Build Log ‚Äî —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –∏ ¬´–ø–∞–∫–µ—Ç¬ª –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞
const ctx = $('Init & Start Timer').item.json;
const chat_id = $json.chat_id ?? ctx.chat_id;
const user_id = $json.user_id ?? ctx.user_id;
const started = $json.started_at ?? ctx.started_at ?? Date.now();
const ended_ms = Date.now();
const latency_ms = ended_ms - started;

// –ü–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å usage –æ—Ç LLM, –µ—Å–ª–∏ –µ—Å—Ç—å
const usage = $json.response?.tokenUsage || $json.tokenUsage || {};
const record = {
  ts: new Date().toISOString(),
  chat_id: String(chat_id),
  user_id: String(user_id ?? ''),
  request_id: $json.request_id ?? ctx.request_id,
  started_at_ms: started,
  ended_at_ms: ended_ms,
  latency_ms,
  status: $json.error ? 'error' : 'ok',
  model: $json.model || 'openrouter',
  tokens_in: usage.promptTokens ?? 0,
  tokens_out: usage.completionTokens ?? 0,
};

return [{
  json: {
    ...$json,
    chat_id, user_id,
    started_at_ms: started,
    ended_at_ms: ended_ms,
    latency_ms,
    packet: record,
    loki_body: {
      streams: [{
        stream: { app: 'n8n-bot', chat_id: String(chat_id), user_id: String(user_id ?? ''), request_id: record.request_id, model: record.model, status: record.status },
        values: [[ String(Date.now()*1e6), JSON.stringify(record) ]]
      }]
    }
  }
}];
```

### `n8n/snippets/make_loki_window.js`

```js
// Make Loki Window ‚Äî –æ–∫–Ω–æ –ø–æ–∏—Å–∫–∞ –ø–æ request_id
const start = Math.max(0, ($json.started_at_ms ?? Date.now()) - 120000);
const end   = ($json.ended_at_ms ?? Date.now()) + 60000;

return [{
  json: {
    ...$json,
    loki_query: `{app="n8n-bot", chat_id="${$json.chat_id}", request_id="${$json.request_id}"} | json`,
    start_ns: String(start * 1e6),
    end_ns:   String(end   * 1e6),
    limit: 1000,
    direction: 'backward'
  }
}];
```

### `n8n/snippets/build_metrics_and_prompt.js`

```js
// –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –æ—Ç–≤–µ—Ç–∞ Loki + —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏ –ø—Ä–æ–º–ø—Ç–∞
const res = $json?.data?.result ?? $json?.body?.data?.result ?? [];
const logs = [];
for (const s of res) for (const [ts, line] of (s.values||[])) {
  try { logs.push(JSON.parse(line)); } catch { logs.push({raw: line}); }
}
// –¥–æ–±–∞–≤–∏–º —Ç–µ–∫—É—â–∏–π –ø–∞–∫–µ—Ç —Å–≤–µ—Ä—Ö—É, –µ—Å–ª–∏ –µ—Å—Ç—å
const packet = $('Build Log').item.json.packet || {};
if (Object.keys(packet).length) logs.unshift(packet);

const lat = logs.map(e => e.latency_ms).filter(n => typeof n === 'number').sort((a,b)=>a-b);
const p95 = lat.length ? Math.trunc(lat[Math.floor(0.95*(lat.length-1))]) : null;
const max = lat.length ? lat[lat.length-1] : null;
const errors = logs.filter(e => e.status==='error'||e.error).length;
const model = (logs.find(e=>e.model)?.model) || 'unknown';
const user_id = logs.find(e=>e.user_id)?.user_id || '';
const request_id = logs.find(e=>e.request_id)?.request_id || (Math.random().toString(36).slice(2,10)).toUpperCase();

const metrics = { count: logs.length, p95_ms: p95, max_ms: max, errors, model, user_id, request_id };

// –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç/–ø–æ–¥—Å–∫–∞–∑–∫–∞ –ø—Ä–∏—á–∏–Ω—ã –∫–æ–¥–æ–º, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ ¬´—Ñ–∞–Ω—Ç–∞–∑–∏—Ä–æ–≤–∞–ª–∞¬ª
let priority = 'S3';
if ((metrics.p95_ms ?? 0) > 6000) priority = 'S1';
else if ((metrics.p95_ms ?? 0) > 3000 || (metrics.errors ?? 0) > 0) priority = 'S2';
let cause_hint = '–Ω–æ—Ä–º–∞–ª—å–Ω–æ';
if ((metrics.errors ?? 0) > 0)                cause_hint = '–æ—à–∏–±–∫–∞ –∫–æ–¥–∞/n8n';
else if ((metrics.p95_ms ?? 0) > 60000)       cause_hint = '—Ç–∞–π–º–∞—É—Ç';
else if ((metrics.p95_ms ?? 0) > 3000)        cause_hint = '–º–µ–¥–ª–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å/–Ω–∞–≥—Ä—É–∑–∫–∞';

const sample = logs.slice(0,20).map(e => JSON.stringify(e).slice(0,300)).join('\n');
const header = `–¢—ã DevOps-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –î–∞–π –æ—Ç—á—ë—Ç (5‚Äì8 —Å—Ç—Ä–æ–∫), –±–µ–∑ Markdown/JSON: —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ; –ø—Ä–∏—á–∏–Ω–∞; —Ñ–∞–∫—Ç—ã; user_id/–º–æ–¥–µ–ª—å/—Ç–æ–∫–µ–Ω—ã; –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç; —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–±—É–ª–ª–µ—Ç–∞–º–∏). –ú–∞–∫—Å 700 —Å–∏–º–≤–æ–ª–æ–≤.`;
const prompt = `${header}\n–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: ${priority}\n–ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø—Ä–∏—á–∏–Ω—ã: ${cause_hint}\n–ú–µ—Ç—Ä–∏–∫–∏: ${JSON.stringify(metrics)}\n–§—Ä–∞–≥–º–µ–Ω—Ç—ã –ª–æ–≥–æ–≤:\n${sample}`;

return [{ json: { ...$json, metrics, priority, cause_hint, request_id, prompt } }];
```

### `n8n/snippets/extract_summary_merge.js`

````js
// –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç—á—ë—Ç–∞
const resp = $json.body ?? $json;
let txt =
  resp?.choices?.[0]?.message?.content ??
  resp?.choices?.[0]?.text ??
  resp?.output_text ?? '';

if (typeof txt !== 'string') txt = String(txt || '');

// —É–±—Ä–∞—Ç—å Markdown-–∑–∞–±–æ—Ä—ã/—É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã
txt = txt.replace(/```[\s\S]*?```/g, '');
txt = txt.replace(/[\u0000-\u001F\u007F]/g, ' ').replace(/\s+\n/g, '\n').trim();

// –º—è–≥–∫–∏–π –ª–∏–º–∏—Ç 700 —Å–∏–º–≤–æ–ª–æ–≤
const LIMIT = 700;
if (txt.length > LIMIT) {
  const cut = txt.slice(0, LIMIT);
  const last = Math.max(cut.lastIndexOf('.'), cut.lastIndexOf('!'), cut.lastIndexOf('?'));
  txt = last >= 100 ? cut.slice(0, last + 1) : cut + '‚Ä¶';
}

if (!txt) {
  const m = $('Build Metrics & Prompt').item.json.metrics ?? {};
  const apiError = resp?.error?.message ?? resp?.error ?? null;
  txt = [
    '–ê–≤—Ç–æ-—Ä–µ–∑—é–º–µ: —Ç–µ–∫—Å—Ç –æ—Ç –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω.',
    `events=${m.count ?? 0}, p95=${m.p95_ms ?? '‚Äî'} ms, max=${m.max_ms ?? '‚Äî'} ms, errors=${m.errors ?? 0}`,
    apiError ? `OpenRouter error: ${apiError}` : 'OpenRouter: –±–µ–∑ —è–≤–Ω–æ–π –æ—à–∏–±–∫–∏'
  ].join('\n');
}

const base = $('Build Metrics & Prompt').item.json;
return [{ json: { ...base, ai_summary: txt } }];
````

### `n8n/snippets/build_report_text.js`

```js
// Build Report Text ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞
const req = $json.request_id  || '(–Ω–µ—Ç id)';
const m = $json.metrics || {};
const text = [
  `üßæ –û—Ç—á—ë—Ç –ø–æ –∑–∞–ø—Ä–æ—Å—É ${req}`,
  `‚Äî —Å–æ–±—ã—Ç–∏–π: ${m.count ?? 0}`,
  `‚Äî p95: ${m.p95_ms ?? '‚Äî'} ms, max: ${m.max_ms ?? '‚Äî'} ms`,
  `‚Äî –æ—à–∏–±–æ–∫: ${m.errors ?? 0}`,
  '',
  $json.ai_summary || '(–Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏)'
].join('\n');

return [{ json: { ...$json, report_text: text } }];
```

### `grafana/provisioning/datasources/datasource.yml`

```yaml
apiVersion: 1

datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    isDefault: true
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
```

### `grafana/provisioning/dashboards/dashboards.yml`

```yaml
apiVersion: 1
providers:
  - name: 'n8n-telegram'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 30
    options:
      path: /var/lib/grafana/dashboards
```

### `grafana/dashboards/n8n-telegram.json`

> –ü—Ä–∏–º–µ—Ä–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ —Å –ø–∞–Ω–µ–ª—è–º–∏: p95 –∑–∞ 15–º, –æ—à–∏–±–∫–∏ –ø–æ –º–æ–¥–µ–ª—è–º –∑–∞ 10–º, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π –ø–æ user –∑–∞ 5–º. –ò—Å–ø–æ–ª—å–∑—É–π –∑–∞–ø—Ä–æ—Å—ã:

```
quantile_over_time(0.95, {app="n8n-bot"} | json | unwrap latency_ms [15m])

sum by (model) (count_over_time({app="n8n-bot",status="error"}[10m]))

sum by (user_id) (count_over_time({app="n8n-bot"}[5m]))
```

(–ò–º–ø–æ—Ä—Ç–∏—Ä—É–π —á–µ—Ä–µ–∑ Grafana ‚Üí Dashboards ‚Üí Import –∏ –ø–æ–¥—Å—Ç–∞–≤—å —Å–≤–æ—é JSON-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é.)

### `loki/config/loki-config.yml`

```yaml
server:
  http_listen_port: 3100
positions:
  filename: /loki/positions.yaml
common:
  path: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h
ruler:
  alertmanager_url: http://localhost:9093
```

### `promtail/config/promtail-config.yml`

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0
positions:
  filename: /tmp/positions.yaml
clients:
  - url: http://loki:3100/loki/api/v1/push
scrape_configs:
  - job_name: docker
    static_configs:
      - targets: [localhost]
        labels:
          job: docker
          __path__: /var/lib/docker/containers/*/*-json.log
```

### `prometheus/prometheus.yml`

```yaml
global:
  scrape_interval: 15s
scrape_configs:
  - job_name: prometheus
    static_configs:
      - targets: ['prometheus:9090']
  - job_name: node_exporter
    static_configs:
      - targets: ['localhost:9100']
```

---

## üß™ –ò–º–ø–æ—Ä—Ç –≤–æ—Ä–∫—Ñ–ª–æ—É n8n

–í `n8n/workflows/*.example.json` –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –∑–∞–≥–ª—É—à–∫–∏. –ò–º–ø–æ—Ä—Ç–∏—Ä—É–π —Å–≤–æ–π —ç–∫—Å–ø–æ—Ä—Ç –∏–ª–∏ —Å–æ–±–µ—Ä–∏ —Å—Ö–µ–º—É, –∏—Å–ø–æ–ª—å–∑—É—è —Å–Ω–∏–ø–ø–µ—Ç—ã –∏–∑ `n8n/snippets`. –ö–ª—é—á–µ–≤—ã–µ —É–∑–ª—ã:

- **Init & Start Timer** ‚Üí `init_start_timer.js`
- **Build Log** ‚Üí `build_log.js`
- **Push to Loki** (HTTP Request) ‚Üí `POST ${LOKI_URL}/loki/api/v1/push`
- **IF Slow?** ‚Üí `{{ Number($json.latency_ms || 0) > 60000 }}`
- **Make Loki Window** ‚Üí `make_loki_window.js`
- **Fetch Loki Window** (HTTP Request) ‚Üí `GET ${LOKI_URL}/loki/api/v1/query_range` (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ `make_loki_window.js`)
- **Build Metrics & Prompt** ‚Üí `build_metrics_and_prompt.js`
- **Analyze** (–æ–ø—Ü., –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–∏ –Ω—É–ª–µ —Ç–æ–∫–µ–Ω–æ–≤) ‚Üí –≤—ã–∑–æ–≤ LLM
- **Extract Summary** ‚Üí `extract_summary_merge.js`
- **Build Report Text** ‚Üí `build_report_text.js`
- **Telegram Send Message** ‚Üí –≤ –∫–∞–Ω–∞–ª (`REPORT_CHAT_ID`), Parse Mode = None

---

## üîê –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –ø—Ä–∞–∫—Ç–∏–∫–∏

- **–°–µ–∫—Ä–µ—Ç—ã** ‚Äî —Ç–æ–ª—å–∫–æ –≤ `.env`/credentials; –Ω–µ –∫–æ–º–º–∏—Ç—å.
- **Telegram Parse Mode** = None (–∏–Ω–∞—á–µ `can't parse entities`).
- **LLM kill switch**: `LLM_ENABLED=0` –æ—Ç–∫–ª—é—á–∏—Ç –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –º–æ–¥–µ–ª–∏ (–≤–µ—Ç–∫—É –æ—Ç—á—ë—Ç–∞ —Ç–æ–∂–µ –º–æ–∂–Ω–æ –∑–∞–≥–ª—É—à–∏—Ç—å).
- **Memory** (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –≤ —á–∞—Ç–æ–≤–æ–π –≤–µ—Ç–∫–µ): Context Window Length = 2, –∫–ª—é—á –ø–æ `chat_id`.
- **–ü—Ä–∞–≤–∞ –±–æ—Ç–∞** –≤ –∫–∞–Ω–∞–ª–µ –æ—Ç—á—ë—Ç–æ–≤: –∫–∞–∫ –º–∏–Ω–∏–º—É–º **Post Messages**.

---

## üß© –¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è

- `Bad Request: chat not found` ‚Üí –Ω–µ–≤–µ—Ä–Ω—ã–π `REPORT_CHAT_ID` –∏–ª–∏ –±–æ—Ç –Ω–µ –∞–¥–º–∏–Ω –∫–∞–Ω–∞–ª–∞.
- `JSON parameter needs to be valid JSON` ‚Üí –≤ HTTP-—É–∑–ª–µ –≤—ã–±–µ—Ä–∏ **Send Body: JSON**.
- Loki 400 parse error ‚Üí –ø—Ä–æ–≤–µ—Ä—å `start/end` –≤ ns (—É–º–Ω–æ–∂–µ–Ω–∏–µ –Ω–∞ `1e6`).
- IF –æ–∂–∏–¥–∞–µ—Ç boolean ‚Üí `{{ Number($json.latency_ms || 0) > 60000 }}` + –æ–ø–µ—Ä–∞—Ç–æ—Ä **is true**.
- Telegram `can't parse entities` ‚Üí Parse Mode = None –∏–ª–∏ —ç–∫—Ä–∞–Ω–∏—Ä—É–π MarkdownV2.
- `Prompt tokens limit exceeded` / ¬´–∂—Ä—ë—Ç —Ç–æ–∫–µ–Ω—ã¬ª ‚Üí –±–µ–∑ AI Agent; Chat Model —Å –¥–≤—É–º—è —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏; Memory K=2.

---

## üß† –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –≤–º–µ—Å—Ç–æ –≤–Ω–µ—à–Ω–µ–π

–ú–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å Ollama/LM Studio:

- **Base URL**: `http://ollama:11434/v1` (–∏–ª–∏ `http://<tailscale-ip>:11434/v1`)
- **Model**: `gemma2:2b-instruct`
- **API Key**: –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `ollama`)

–°–º–æ—Ç—Ä–∏ —Ç–∞–∫–∂–µ: `LLM_BASE_URL`, `LLM_MODEL`, `LLM_API_KEY` –≤ `.env`.

---

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT (–Ω–∞ –≤–∞—à–µ —É—Å–º–æ—Ç—Ä–µ–Ω–∏–µ).



---

# bot-and-reports.example.json

–ù–∏–∂–µ ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π, **—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π** –≤–æ—Ä–∫—Ñ–ª–æ—É –±–µ–∑ Agent-–Ω–æ–¥. –û–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º OpenAI‚Äë—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º LLM (OpenRouter, Ollama, LM Studio) —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

- `LLM_BASE_URL` ‚Äî –±–∞–∑–æ–≤—ã–π URL (`https://openrouter.ai/api/v1` –∏–ª–∏ `http://ollama:11434/v1` –∏ —Ç.–ø.)
- `LLM_API_KEY` ‚Äî –∫–ª—é—á (–¥–ª—è Ollama/LM Studio –º–æ–∂–Ω–æ –∑–∞–≥–ª—É—à–∫—É `local`)
- `LLM_MODEL` ‚Äî –∏–º—è –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `google/gemini-2.5-flash-lite` –∏–ª–∏ `gemma2:2b-instruct`)
- `LLM_ENABLED` ‚Äî `1`/`0` –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—á—ë—Ç–æ–≤
- `SLOW_THRESHOLD_MS` ‚Äî –ø–æ—Ä–æ–≥ –º–µ–¥–ª–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60000)
- `LOKI_URL`, `REPORT_CHAT_ID` ‚Äî Loki –∏ –∫–∞–Ω–∞–ª –æ—Ç—á—ë—Ç–æ–≤

> –ü–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º —É–±–µ–¥–∏—Å—å, —á—Ç–æ –≤ n8n –∑–∞–¥–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (—á–µ—Ä–µ–∑ `.env` –∏–ª–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ). –ü–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ –ø—Ä–æ—Å—Ç–æ –≤—ã–±–µ—Ä–∏ –∫—Ä–µ–¥—ã –¥–ª—è Telegram.

```json
{
  "name": "bot-and-reports (example)",
  "nodes": [
    {
      "parameters": {},
      "name": "Telegram Trigger",
      "type": "n8n-nodes-base.telegramTrigger",
      "typeVersion": 1,
      "position": [-1200, -600]
    },
    {
      "parameters": {
        "jsCode": "// –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥ –∏ —Å—Ç–∞–≤–∏–º –º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏ —Å—Ç–∞—Ä—Ç–∞
const m = $json.message || $json.edited_message || {};
const started = Date.now();
const reqId = Math.random().toString(36).slice(2,10).toUpperCase();
return [{ json: {
  started_at: started,
  chat_id: m.chat?.id,
  user_id: m.from?.id,
  message_id: m.message_id,
  text: (m.text ?? '').slice(0, 1500),
  request_id: reqId
}}];"
      },
      "name": "Init & Start Timer",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-960, -600]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{$env.LLM_BASE_URL}}/chat/completions",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            { "name": "Authorization", "value": "=Bearer {{$env.LLM_API_KEY}}" },
            { "name": "Content-Type", "value": "application/json" }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  \"model\": \"={{$env.LLM_MODEL}}\",
  \"messages\": [
    { \"role\": \"system\", \"content\": \"–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –ø–æ-—Ä—É—Å—Å–∫–∏. –ë–µ–∑ Markdown –∏ JSON.\" },
    { \"role\": \"user\", \"content\": \"={{ $item(0).$node['Init & Start Timer'].json.text || $item(0).$node['Telegram Trigger'].json.message.text || '' }}\" }
  ],
  \"temperature\": 0.2,
  \"max_tokens\": {{ Number($env.LLM_MAX_TOKENS || 120) }}
}"
      },
      "name": "Chat LLM (HTTP)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [-720, -600]
    },
    {
      "parameters": {
        "jsCode": "const resp = $json.body ?? $json;
let txt = resp?.choices?.[0]?.message?.content ?? resp?.choices?.[0]?.text ?? resp?.output_text ?? '';
return [{ json: { ...$json, reply_text: String(txt||'').trim() || '–ì–æ—Ç–æ–≤ –ø–æ–º–æ—á—å.' } }];"
      },
      "name": "Ensure Text",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-520, -600]
    },
    {
      "parameters": {
        "chatId": "={{ $json.chat_id || $item(0).$node['Init & Start Timer'].json.chat_id || $json.message?.chat?.id }}",
        "text": "={{ $json.reply_text }}",
        "additionalFields": { "appendAttribution": false, "parse_mode": "None" }
      },
      "name": "Telegram Send Reply",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [-320, -600]
    },
    {
      "parameters": {
        "jsCode": "// Build Log ‚Äî —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –∏ –ø–∞–∫–µ—Ç –¥–ª—è Loki
const init = $('Init & Start Timer').item.json;
const ended_ms = Date.now();
const latency_ms = ended_ms - init.started_at;
const resp = $json.body ?? $json;
const usage = resp?.usage || {};
const record = {
  ts: new Date().toISOString(),
  chat_id: String(init.chat_id),
  user_id: String(init.user_id||''),
  request_id: String(init.request_id),
  started_at_ms: init.started_at,
  ended_at_ms,
  latency_ms,
  status: 'ok',
  model: String($env.LLM_MODEL || 'llm'),
  tokens_in: usage.prompt_tokens ?? usage.inputTokens ?? 0,
  tokens_out: usage.completion_tokens ?? usage.outputTokens ?? 0,
  reply_text: String($json.reply_text||'').slice(0, 4000)
};
return [{ json: {
  ...$json,
  latency_ms,
  loki_body: { streams: [{
    stream: { app: 'n8n-bot', chat_id: record.chat_id, user_id: record.user_id, request_id: record.request_id, model: record.model, status: record.status },
    values: [[ String(Date.now()*1e6), JSON.stringify(record) ]]
  }]}
}}];"
      },
      "name": "Build Log",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-720, -360]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{$env.LOKI_URL}}/loki/api/v1/push",
        "sendHeaders": true,
        "headerParameters": { "parameters": [ {"name": "Content-Type", "value": "application/json"} ] },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.loki_body }}"
      },
      "name": "Push to Loki",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [-520, -360]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "version": 2 },
          "conditions": [
            { "leftValue": "={{ Number($json.latency_ms || 0) > Number($env.SLOW_THRESHOLD_MS || 60000) }}", "operator": {"type":"boolean","operation":"true","singleValue": true} }
          ],
          "combinator": "and"
        }
      },
      "name": "Slow? > threshold",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [-320, -360]
    },
    {
      "parameters": {
        "jsCode": "// –æ–∫–Ω–æ –ø–æ–∏—Å–∫–∞ –ø–æ chat_id+request_id
const init = $('Init & Start Timer').item.json;
const start = Math.max(0, init.started_at - 120000);
const end   = Date.now() + 60000;
return [{ json: {
  chat_id: String(init.chat_id),
  request_id: String(init.request_id),
  loki_query: `{app=\\"n8n-bot\\", chat_id=\\"${init.chat_id}\\", request_id=\\"${init.request_id}\\"} | json`,
  start_ns: String(start*1e6),
  end_ns: String(end*1e6),
  limit: 1000,
  direction: 'backward'
}}];"
      },
      "name": "Make Loki Window",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-120, -360]
    },
    {
      "parameters": {
        "url": "={{$env.LOKI_URL}}/loki/api/v1/query_range",
        "sendQuery": true,
        "queryParameters": { "parameters": [
          {"name":"query","value":"={{$json.loki_query}}"},
          {"name":"start","value":"={{$json.start_ns}}"},
          {"name":"end","value":"={{$json.end_ns}}"},
          {"name":"limit","value":"={{$json.limit}}"},
          {"name":"direction","value":"backward"}
        ]}
      },
      "name": "Fetch Loki Window",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [80, -360],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "// –ø–∞—Ä—Å–∏–º Loki + –º–µ—Ç—Ä–∏–∫–∏ + –ø—Ä–æ–º–ø—Ç
const res = $json?.data?.result ?? $json?.body?.data?.result ?? [];
const logs = [];
for (const s of res) for (const [ts, line] of (s.values||[])) { try { logs.push(JSON.parse(line)); } catch { logs.push({raw: line}); } }
const lat = logs.map(e=>e.latency_ms).filter(n=>typeof n==='number').sort((a,b)=>a-b);
const p95 = lat.length ? Math.trunc(lat[Math.floor(0.95*(lat.length-1))]) : null;
const max = lat.length ? lat[lat.length-1] : null;
const errors = logs.filter(e=>e.status==='error'||e.error).length;
const model = (logs.find(e=>e.model)?.model) || 'unknown';
const user_id = logs.find(e=>e.user_id)?.user_id || '';
const request_id = logs.find(e=>e.request_id)?.request_id || $('Init & Start Timer').item.json.request_id;
const sample = logs.slice(0,20).map(e => JSON.stringify(e).slice(0,300)).join('\n');
const metrics = { count: logs.length, p95_ms: p95, max_ms: max, errors, model, user_id, request_id };
const header = `–¢—ã DevOps-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –î–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç (5‚Äì8 —Å—Ç—Ä–æ–∫), –±–µ–∑ Markdown/JSON.`;
const prompt = `${header}\n–ú–µ—Ç—Ä–∏–∫–∏: ${JSON.stringify(metrics)}\n–§—Ä–∞–≥–º–µ–Ω—Ç—ã –ª–æ–≥–æ–≤:${sample ? '\n'+sample : ' (–ø—É—Å—Ç–æ)'}\n`;
return [{ json: { ...$json, metrics, request_id, prompt } }];"
      },
      "name": "Build Metrics & Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [280, -360]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "version": 2 },
          "conditions": [ { "leftValue": "={{ String($env.LLM_ENABLED || '1') === '1' }}", "operator": {"type":"boolean","operation":"true","singleValue": true} } ],
          "combinator": "and"
        }
      },
      "name": "LLM enabled?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [480, -360]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "={{$env.LLM_BASE_URL}}/chat/completions",
        "sendHeaders": true,
        "headerParameters": { "parameters": [
          { "name": "Authorization", "value": "=Bearer {{$env.LLM_API_KEY}}" },
          { "name": "Content-Type", "value": "application/json" }
        ] },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={
  \"model\": \"={{$env.LLM_MODEL}}\",
  \"messages\": [
    { \"role\": \"system\", \"content\": \"–¢—ã DevOps-–ø–æ–º–æ—â–Ω–∏–∫. –ë—É–¥—å –∫—Ä–∞—Ç–∫–∏–º –∏ –ø–æ –¥–µ–ª—É.\" },
    { \"role\": \"user\", \"content\": \"={{$json.prompt}}\" }
  ],
  \"temperature\": 0.2,
  \"max_tokens\": 180
}"
      },
      "name": "OpenRouter Analyze (HTTP)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [680, -440],
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "jsCode": "const resp = $json.body ?? $json;
let txt = resp?.choices?.[0]?.message?.content ?? resp?.choices?.[0]?.text ?? resp?.output_text ?? '';
if (typeof txt !== 'string') txt = String(txt||'');
const m = $('Build Metrics & Prompt').item.json.metrics || {};
if (!txt.trim()) txt = `–ê–≤—Ç–æ-—Ä–µ–∑—é–º–µ: —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç. events=${m.count||0}, p95=${m.p95_ms||'‚Äî'} ms, max=${m.max_ms||'‚Äî'} ms, errors=${m.errors||0}`;
return [{ json: { ...$('Build Metrics & Prompt').item.json, ai_summary: txt } }];"
      },
      "name": "Extract Summary",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [880, -440]
    },
    {
      "parameters": {
        "jsCode": "const m = $json.metrics || {};
const text = [
  `üßæ –û—Ç—á—ë—Ç –ø–æ –∑–∞–ø—Ä–æ—Å—É ${$json.request_id || '(–Ω–µ—Ç id)'}`,
  `‚Äî —Å–æ–±—ã—Ç–∏–π: ${m.count ?? 0}`,
  `‚Äî p95: ${m.p95_ms ?? '‚Äî'} ms, max: ${m.max_ms ?? '‚Äî'} ms`,
  `‚Äî –æ—à–∏–±–æ–∫: ${m.errors ?? 0}`,
  '',
  $json.ai_summary || '(–Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏)'
].join('\n');
return [{ json: { ...$json, report_text: text } }];"
      },
      "name": "Build Report Text",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1080, -440]
    },
    {
      "parameters": {
        "chatId": "={{$env.REPORT_CHAT_ID}}",
        "text": "={{$json.report_text}}",
        "additionalFields": { "appendAttribution": false, "parse_mode": "None" }
      },
      "name": "Telegram Send Report",
      "type": "n8n-nodes-base.telegram",
      "typeVersion": 1.2,
      "position": [1280, -440]
    }
  ],
  "connections": {
    "Telegram Trigger": { "main": [[{ "node": "Init & Start Timer", "type": "main", "index": 0 }]] },
    "Init & Start Timer": { "main": [[{ "node": "Chat LLM (HTTP)", "type": "main", "index": 0 }]] },
    "Chat LLM (HTTP)": { "main": [[{ "node": "Ensure Text", "type": "main", "index": 0 }]] },
    "Ensure Text": { "main": [[{ "node": "Telegram Send Reply", "type": "main", "index": 0 }, { "node": "Build Log", "type": "main", "index": 0 }]] },
    "Build Log": { "main": [[{ "node": "Push to Loki", "type": "main", "index": 0 }, { "node": "Slow? > threshold", "type": "main", "index": 0 }]] },
    "Slow? > threshold": { "main": [[{ "node": "Make Loki Window", "type": "main", "index": 0 }]] },
    "Make Loki Window": { "main": [[{ "node": "Fetch Loki Window", "type": "main", "index": 0 }]] },
    "Fetch Loki Window": { "main": [[{ "node": "Build Metrics & Prompt", "type": "main", "index": 0 }]] },
    "Build Metrics & Prompt": { "main": [[{ "node": "LLM enabled?", "type": "main", "index": 0 }]] },
    "LLM enabled?": { "main": [[{ "node": "OpenRouter Analyze (HTTP)", "type": "main", "index": 0 }]] },
    "OpenRouter Analyze (HTTP)": { "main": [[{ "node": "Extract Summary", "type": "main", "index": 0 }]] },
    "Extract Summary": { "main": [[{ "node": "Build Report Text", "type": "main", "index": 0 }]] },
    "Build Report Text": { "main": [[{ "node": "Telegram Send Report", "type": "main", "index": 0 }]] }
  },
  "active": false,
  "settings": { "executionOrder": "v1" }
}
```

## .env.example (–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è)

```dotenv
# LLM (–ª—é–±–æ–π OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_API_KEY=sk-or-...
LLM_MODEL=google/gemini-2.5-flash-lite
LLM_MAX_TOKENS=120
LLM_ENABLED=1
SLOW_THRESHOLD_MS=60000

# Loki / Reports
LOKI_URL=http://loki:3100
REPORT_CHAT_ID=-100xxxxxxxxxx
```

**–ò–º–ø–æ—Ä—Ç**: –≤ n8n ‚Üí Settings ‚Üí Import from file ‚Üí –≤—ã–±–µ—Ä–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ JSON –≤—ã—à–µ. –ü–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ –Ω–∞–∑–Ω–∞—á—å –∫—Ä–µ–¥—ã Telegram —É –¥–≤—É—Ö –Ω–æ–¥ ¬´Telegram ‚Ä¶¬ª.

